300 -156.33706057752667 3 5.0 108 8 3 [118, 64] True 0 3 [108, 16, 16] [0. 0. 0. 0.] True
contracted_coeff torch.Size([1, 3, 8, 108]) Parameter containing:
tensor([[[[ 0.0361,  0.0165,  0.0196,  ...,  0.0122, -0.0021, -0.0274],
          [ 0.0276,  0.0211,  0.0118,  ..., -0.0243, -0.0085,  0.0102],
          [ 0.0198,  0.0254, -0.0187,  ..., -0.0235,  0.0400, -0.0175],
          ...,
          [-0.0053,  0.0169, -0.0025,  ...,  0.0057, -0.0010,  0.0059],
          [-0.0078, -0.0292,  0.0250,  ..., -0.0329, -0.0307, -0.0214],
          [ 0.0090, -0.0063, -0.0321,  ...,  0.0033,  0.0077,  0.0319]],

         [[-0.0348, -0.0146,  0.0046,  ..., -0.0171, -0.0365, -0.0169],
          [-0.0100, -0.0250,  0.0226,  ..., -0.0017,  0.0108,  0.0340],
          [-0.0309, -0.0175,  0.0027,  ..., -0.0324,  0.0267, -0.0134],
          ...,
          [ 0.0112,  0.0256,  0.0091,  ..., -0.0216, -0.0298, -0.0157],
          [-0.0353,  0.0096, -0.0222,  ..., -0.0108, -0.0333,  0.0284],
          [ 0.0090,  0.0002, -0.0135,  ..., -0.0388,  0.0323, -0.0273]],

         [[-0.0082, -0.0363,  0.0148,  ..., -0.0175, -0.0335, -0.0085],
          [-0.0347,  0.0078, -0.0219,  ..., -0.0047,  0.0175, -0.0338],
          [-0.0253,  0.0009,  0.0220,  ...,  0.0025, -0.0081,  0.0087],
          ...,
          [ 0.0204, -0.0199, -0.0045,  ..., -0.0081, -0.0206,  0.0083],
          [-0.0066, -0.0229,  0.0169,  ..., -0.0407, -0.0036, -0.0283],
          [ 0.0027,  0.0095,  0.0238,  ..., -0.0335, -0.0388, -0.0298]]]],
       device='cuda:0', requires_grad=True)
emb_neighnn.net.0.weight torch.Size([64, 118]) Parameter containing:
tensor([[ 0.1069, -0.0392,  0.1132,  ...,  0.1807, -0.1185,  0.0127],
        [ 0.1029, -0.1232, -0.1064,  ...,  0.0407, -0.0229, -0.0168],
        [ 0.0313, -0.1411,  0.0894,  ...,  0.1740, -0.1530,  0.0198],
        ...,
        [-0.0039, -0.0632, -0.1495,  ..., -0.1709,  0.0887,  0.0039],
        [ 0.0393, -0.1793, -0.1524,  ..., -0.0140, -0.0393, -0.0138],
        [-0.1342,  0.0528,  0.0991,  ..., -0.0884,  0.1610, -0.0953]],
       device='cuda:0', requires_grad=True)
emb_neighnn.net.0.bias torch.Size([64]) Parameter containing:
tensor([ 0.0031,  0.0516, -0.0094,  0.0187,  0.0873, -0.0808,  0.0899,  0.0218,
         0.0563, -0.0809,  0.0832, -0.0131,  0.0549,  0.0399, -0.0086, -0.0464,
         0.0615, -0.0479, -0.0324,  0.0042,  0.0825,  0.0356,  0.0518,  0.0903,
        -0.0567, -0.0310, -0.0007,  0.0855, -0.0719, -0.0322, -0.0245, -0.0002,
         0.0211,  0.0205, -0.0874, -0.0061,  0.0626, -0.0515,  0.0432,  0.0834,
        -0.0629,  0.0459, -0.0801, -0.0113, -0.0269, -0.0225,  0.0671,  0.0872,
        -0.0495, -0.0005, -0.0241, -0.0504,  0.0172,  0.0133, -0.0505,  0.0073,
         0.0636, -0.0412, -0.0871, -0.0699, -0.0013, -0.0661, -0.0711, -0.0522],
       device='cuda:0', requires_grad=True)
emb_neighnn.net.4.alpha torch.Size([1, 64]) Parameter containing:
tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], device='cuda:0',
       requires_grad=True)
emb_neighnn.net.4.beta torch.Size([1, 64]) Parameter containing:
tensor([[0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085,
         0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085,
         0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085,
         0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085,
         0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085,
         0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085,
         0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085,
         0.0085]], device='cuda:0', requires_grad=True)
emb_neighnn.net.5.weight torch.Size([24, 64]) Parameter containing:
tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', requires_grad=True)
emb_neighnn.net.5.bias torch.Size([24]) Parameter containing:
tensor([ 6.4746e-03, -3.3212e-03,  4.7928e-03, -1.8252e-05,  4.5581e-03,
         4.9337e-03,  1.2289e-03, -1.3183e-03,  1.0000e+00,  1.0000e+00,
         1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,
         1.0000e+00,  3.4685e-01,  1.3835e+00,  5.7080e-01,  1.1898e-01,
         2.0798e+00,  5.3476e-01,  2.1683e+00,  4.3975e-01], device='cuda:0',
       requires_grad=True)
emb_centernn.net.0.weight torch.Size([64, 118]) Parameter containing:
tensor([[-0.0094,  0.0734, -0.0483,  ...,  0.0744,  0.1481, -0.0281],
        [-0.0680,  0.0368, -0.1690,  ..., -0.1802,  0.0960,  0.1807],
        [ 0.0317, -0.1631,  0.1719,  ...,  0.1723, -0.1679, -0.0924],
        ...,
        [ 0.0677,  0.1529,  0.0242,  ...,  0.0644,  0.1706,  0.1743],
        [-0.0523, -0.1588,  0.0968,  ...,  0.0331,  0.1747,  0.1552],
        [ 0.1699,  0.1323,  0.1364,  ..., -0.1285,  0.0611, -0.0281]],
       device='cuda:0', requires_grad=True)
emb_centernn.net.0.bias torch.Size([64]) Parameter containing:
tensor([ 0.0827,  0.0805,  0.0819, -0.0792, -0.0340, -0.0828,  0.0111, -0.0337,
         0.0353,  0.0394, -0.0397, -0.0234,  0.0296, -0.0893, -0.0790,  0.0262,
        -0.0507, -0.0785,  0.0398, -0.0761, -0.0147,  0.0883, -0.0172,  0.0235,
         0.0219,  0.0086, -0.0584,  0.0178,  0.0001, -0.0614, -0.0584,  0.0879,
        -0.0489,  0.0739, -0.0255, -0.0167, -0.0501,  0.0056,  0.0755,  0.0777,
        -0.0623, -0.0247,  0.0581, -0.0196, -0.0307, -0.0505,  0.0618,  0.0826,
         0.0614,  0.0071,  0.0666,  0.0185,  0.0744,  0.0211,  0.0599,  0.0012,
         0.0347, -0.0244, -0.0731,  0.0385,  0.0617,  0.0719, -0.0162,  0.0363],
       device='cuda:0', requires_grad=True)
emb_centernn.net.4.alpha torch.Size([1, 64]) Parameter containing:
tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], device='cuda:0',
       requires_grad=True)
emb_centernn.net.4.beta torch.Size([1, 64]) Parameter containing:
tensor([[0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085,
         0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085,
         0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085,
         0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085,
         0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085,
         0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085,
         0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085, 0.0085,
         0.0085]], device='cuda:0', requires_grad=True)
emb_centernn.net.5.weight torch.Size([108, 64]) Parameter containing:
tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', requires_grad=True)
emb_centernn.net.5.bias torch.Size([108]) Parameter containing:
tensor([ 2.3295e-03, -4.3966e-03, -7.1578e-03, -2.4964e-03,  1.5522e-03,
         5.6052e-03, -3.3822e-03, -4.6898e-04, -2.5206e-03, -1.1830e-03,
        -3.6461e-03,  1.2569e-03,  1.6214e-03, -3.9728e-03, -5.0902e-04,
        -4.2859e-03, -2.5676e-03, -4.5654e-03,  8.0449e-04,  3.3209e-03,
        -1.0181e-03, -2.0035e-03, -8.9993e-04, -9.7402e-04, -1.2786e-03,
        -3.6881e-03,  5.0232e-03,  2.2725e-03, -3.5136e-03, -2.9437e-03,
        -5.6369e-04,  3.8935e-03,  1.5442e-03, -6.4867e-04, -6.9868e-03,
        -4.2836e-03,  4.4776e-03, -1.2601e-04, -3.2979e-03,  4.2806e-03,
         5.5687e-03,  2.0988e-03,  8.2681e-04, -3.6185e-04, -4.0551e-03,
        -2.3287e-03, -8.3693e-04,  3.1806e-03, -3.8485e-04,  2.9890e-03,
        -3.7392e-03, -1.1859e-03,  2.3730e-03, -4.7205e-03, -5.6771e-04,
        -7.5768e-04, -1.9091e-03,  4.1511e-03, -1.3205e-03, -2.9073e-03,
         3.4048e-03, -4.6902e-03,  1.2569e-03, -3.9797e-03,  3.8329e-03,
        -5.1975e-04,  9.8695e-05, -2.5721e-03, -2.0155e-03, -6.8849e-03,
        -9.8396e-03, -2.6027e-03,  2.9662e-03,  2.7428e-03, -2.6949e-03,
        -1.5883e-03, -3.0397e-03, -7.7726e-03,  1.0673e-03, -3.1880e-03,
        -3.3965e-03,  5.0406e-06,  2.5029e-03,  1.8817e-03,  2.0351e-03,
        -1.0831e-04,  1.3297e-03, -2.4662e-03,  2.7225e-03, -2.8207e-04,
        -2.6669e-03, -1.3154e-03,  3.7491e-03,  2.8389e-03,  1.5678e-03,
        -1.6880e-03, -4.4604e-03,  1.6739e-03, -4.4202e-03,  4.4749e-03,
         2.0490e-03,  4.0151e-03,  1.7720e-03,  4.0919e-03,  3.9935e-03,
         1.1990e-03,  2.3121e-03, -1.3187e-03], device='cuda:0',
       requires_grad=True)
outnn.net.0.weight torch.Size([32, 108]) Parameter containing:
tensor([[-0.1575,  0.1127, -0.1872,  ...,  0.0448,  0.0949, -0.1937],
        [-0.1671,  0.0292,  0.1817,  ...,  0.0372, -0.0757,  0.0665],
        [-0.1697,  0.1008,  0.0889,  ..., -0.0802, -0.0705,  0.0738],
        ...,
        [-0.1078, -0.0363,  0.0236,  ..., -0.0108,  0.1276,  0.1627],
        [ 0.1802, -0.1538,  0.0369,  ...,  0.1523,  0.2004,  0.0411],
        [ 0.1642,  0.0403,  0.0262,  ..., -0.1090, -0.0452,  0.1145]],
       device='cuda:0', requires_grad=True)
outnn.net.0.bias torch.Size([32]) Parameter containing:
tensor([ 0.0360,  0.0382,  0.0340,  0.0723,  0.0310,  0.0464,  0.0504,  0.0507,
        -0.0279,  0.0435, -0.0059,  0.0691,  0.0528,  0.0131, -0.0721,  0.0857,
        -0.0822,  0.0824, -0.0919, -0.0269,  0.0582, -0.0450, -0.0243,  0.0599,
        -0.0800, -0.0314,  0.0887,  0.0480,  0.0381,  0.0397,  0.0773,  0.0106],
       device='cuda:0', requires_grad=True)
outnn.net.1.resblock.0.alpha torch.Size([1, 32]) Parameter containing:
tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],
       device='cuda:0', requires_grad=True)
outnn.net.1.resblock.0.beta torch.Size([1, 32]) Parameter containing:
tensor([[0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,
         0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,
         0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,
         0.0093, 0.0093, 0.0093, 0.0093, 0.0093]], device='cuda:0',
       requires_grad=True)
outnn.net.1.resblock.1.weight torch.Size([32]) Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       device='cuda:0', requires_grad=True)
outnn.net.1.resblock.1.bias torch.Size([32]) Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
outnn.net.1.resblock.2.weight torch.Size([16, 32]) Parameter containing:
tensor([[-0.0284,  0.1142,  0.0449,  0.0831,  0.1182, -0.2931, -0.2808, -0.1010,
         -0.1214, -0.3019, -0.1278, -0.0827, -0.3023,  0.1396,  0.3528, -0.2805,
          0.1266,  0.3330, -0.1983, -0.2160, -0.3123, -0.1842,  0.3516,  0.0955,
          0.0638,  0.2825,  0.0824,  0.2588,  0.2982,  0.3254, -0.3502,  0.0317],
        [-0.0915, -0.0330,  0.2871, -0.2724, -0.1607,  0.2271, -0.0809, -0.2822,
          0.2674,  0.2023, -0.1242, -0.0053, -0.0798,  0.3352, -0.0490, -0.1194,
         -0.0313,  0.2641,  0.0979, -0.2580, -0.2191, -0.0849, -0.2855,  0.1965,
          0.3039,  0.1265,  0.1825, -0.1220, -0.2253,  0.2457,  0.2818, -0.2480],
        [ 0.1763,  0.1234,  0.2786, -0.1080, -0.2674, -0.0275, -0.1969,  0.2354,
         -0.1033, -0.1398, -0.0861, -0.1319,  0.1474, -0.1095, -0.3277,  0.0170,
          0.2777,  0.0962,  0.0758, -0.1629,  0.2893,  0.1493,  0.0682, -0.0070,
          0.1349, -0.1165, -0.3114, -0.3380, -0.3006, -0.3421, -0.1912, -0.0943],
        [-0.2896, -0.0762,  0.1550,  0.2464, -0.3379, -0.1198,  0.1251,  0.0970,
          0.2688, -0.1411,  0.1682,  0.1264,  0.0684,  0.2351, -0.1685, -0.2347,
          0.3108,  0.2555, -0.1319, -0.0208, -0.2828,  0.2413,  0.2391, -0.0230,
         -0.2710,  0.1730, -0.3458,  0.0045,  0.1225, -0.2195,  0.2419,  0.1565],
        [-0.0939,  0.3098,  0.2186, -0.1730, -0.2911, -0.0763, -0.0219, -0.3314,
          0.0653, -0.0297, -0.3503,  0.1303,  0.1389, -0.2429, -0.1520, -0.2723,
          0.1108, -0.3263,  0.1514,  0.2050,  0.0098,  0.0955, -0.1690, -0.1354,
         -0.0529,  0.2790, -0.3379,  0.1693, -0.1101,  0.1036, -0.2133,  0.0783],
        [-0.2584, -0.0730, -0.2536,  0.1781, -0.0519, -0.0377,  0.1931, -0.0145,
          0.1104, -0.0864, -0.3416,  0.0147,  0.2954,  0.0212, -0.3354,  0.0790,
          0.3464,  0.1122,  0.1001,  0.0862, -0.3126, -0.1171, -0.2486,  0.2945,
         -0.3118,  0.1277, -0.1110,  0.2983,  0.1845,  0.1429,  0.0508,  0.2458],
        [ 0.1119,  0.1286, -0.0533, -0.3039, -0.1320,  0.1585, -0.1833, -0.1758,
          0.1468, -0.0938, -0.3179, -0.2084,  0.2385, -0.2955, -0.1010,  0.2374,
         -0.3104,  0.0715,  0.2997, -0.1048, -0.3466,  0.0084,  0.1994,  0.1825,
         -0.2818,  0.0413,  0.0764,  0.2359, -0.1668,  0.2932,  0.1404, -0.1283],
        [ 0.0207,  0.3212, -0.2475, -0.0777,  0.1807, -0.2959, -0.1214, -0.0297,
          0.3534,  0.2915, -0.2728,  0.1977,  0.2759,  0.1828, -0.1869,  0.3115,
         -0.0247,  0.0527, -0.1858,  0.1995, -0.0415, -0.1781, -0.0562, -0.3091,
          0.3365,  0.0635,  0.2664,  0.3259, -0.0630,  0.0908, -0.1250,  0.3148],
        [ 0.2792,  0.1164, -0.1433, -0.2569,  0.2362, -0.1082,  0.3315,  0.2621,
         -0.1809, -0.2665, -0.2176,  0.1810, -0.1631, -0.2461, -0.2877,  0.3104,
         -0.2026,  0.2373,  0.0168,  0.2910, -0.1895, -0.3522, -0.3386,  0.2246,
          0.0672, -0.2032,  0.2697, -0.0057,  0.1894, -0.1622,  0.3243, -0.0014],
        [ 0.2206,  0.3481,  0.1849, -0.2025,  0.2015, -0.3251,  0.2466,  0.1895,
          0.2342,  0.2495, -0.2436,  0.1183,  0.3090, -0.2325, -0.3169,  0.2304,
         -0.1111,  0.0299, -0.1399, -0.3466, -0.2633,  0.1036,  0.3477, -0.1662,
         -0.1562,  0.1045,  0.1245,  0.1223, -0.2793, -0.2931,  0.0225, -0.1852],
        [-0.3217, -0.0741,  0.3082,  0.2084,  0.1947, -0.0021, -0.1287,  0.0783,
         -0.0325,  0.3012, -0.3525,  0.1106, -0.3387,  0.0963, -0.0422,  0.2122,
         -0.0915, -0.0251,  0.0706, -0.1356,  0.0090,  0.2584,  0.1494,  0.2308,
         -0.1336, -0.1728, -0.1701,  0.1880,  0.0445, -0.1474, -0.2760,  0.3129],
        [-0.2030, -0.1784, -0.1424,  0.2163, -0.0138, -0.2531, -0.2965,  0.2639,
         -0.3408, -0.1593,  0.0894, -0.1197,  0.2382,  0.0657,  0.3085, -0.1497,
          0.1307,  0.0419,  0.0750, -0.1772, -0.2222, -0.0285,  0.2405, -0.0831,
         -0.0855,  0.2450, -0.1611,  0.0021,  0.1641,  0.1640,  0.3113, -0.1992],
        [ 0.3433, -0.0640,  0.2306, -0.0006, -0.2520, -0.3215,  0.3222, -0.0496,
         -0.1920, -0.1013,  0.0548,  0.1268,  0.0478,  0.2620, -0.1538, -0.2238,
          0.2442, -0.3433,  0.1556,  0.0106,  0.3357,  0.1985, -0.2228,  0.1917,
          0.0865,  0.1148,  0.1043, -0.2651,  0.1514,  0.3000, -0.0320, -0.2514],
        [ 0.1622,  0.1508, -0.2802, -0.1209, -0.0065, -0.3060,  0.0358,  0.0927,
         -0.0463, -0.3018,  0.1209,  0.1818,  0.3525, -0.0918, -0.2411,  0.0296,
         -0.2733, -0.1733,  0.1964, -0.1110,  0.2469, -0.2322,  0.2801, -0.2103,
          0.2917, -0.1073,  0.2889, -0.1702,  0.0173, -0.0547,  0.2485, -0.0854],
        [-0.2175, -0.1436,  0.0043, -0.3334, -0.1830,  0.2591, -0.1570,  0.2228,
         -0.0362,  0.2387, -0.0134,  0.1883, -0.1898,  0.0314, -0.0694,  0.0205,
         -0.1358,  0.0292,  0.0050,  0.0343,  0.0895, -0.1614, -0.3133,  0.1963,
          0.0492,  0.0174,  0.2228, -0.0812,  0.1190,  0.1431, -0.1911, -0.1963],
        [ 0.2510,  0.2640, -0.0747,  0.0274, -0.2188, -0.2997,  0.0174, -0.3456,
          0.3446,  0.0185, -0.2279,  0.2143,  0.1117,  0.2951, -0.0659, -0.2266,
         -0.1972, -0.0805,  0.2260,  0.0452, -0.1076,  0.0850, -0.3124,  0.2806,
          0.2250, -0.1415, -0.0835,  0.1941, -0.0211,  0.0419,  0.0538, -0.2952]],
       device='cuda:0', requires_grad=True)
outnn.net.1.resblock.2.bias torch.Size([16]) Parameter containing:
tensor([-0.0757, -0.0373,  0.0188,  0.1351, -0.1604,  0.1605,  0.0496, -0.0409,
        -0.0442,  0.0301,  0.1748, -0.0133,  0.0440, -0.0768, -0.1572,  0.1732],
       device='cuda:0', requires_grad=True)
outnn.net.1.resblock.3.alpha torch.Size([1, 16]) Parameter containing:
tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],
       device='cuda:0', requires_grad=True)
outnn.net.1.resblock.3.beta torch.Size([1, 16]) Parameter containing:
tensor([[0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312,
         0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312]],
       device='cuda:0', requires_grad=True)
outnn.net.1.resblock.4.weight torch.Size([16]) Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       device='cuda:0', requires_grad=True)
outnn.net.1.resblock.4.bias torch.Size([16]) Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
outnn.net.1.resblock.5.weight torch.Size([32, 16]) Parameter containing:
tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],
       device='cuda:0', requires_grad=True)
outnn.net.1.resblock.5.bias torch.Size([32]) Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
outnn.net.2.resblock.0.alpha torch.Size([1, 32]) Parameter containing:
tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],
       device='cuda:0', requires_grad=True)
outnn.net.2.resblock.0.beta torch.Size([1, 32]) Parameter containing:
tensor([[0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,
         0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,
         0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,
         0.0093, 0.0093, 0.0093, 0.0093, 0.0093]], device='cuda:0',
       requires_grad=True)
outnn.net.2.resblock.1.weight torch.Size([32]) Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       device='cuda:0', requires_grad=True)
outnn.net.2.resblock.1.bias torch.Size([32]) Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
outnn.net.2.resblock.2.weight torch.Size([16, 32]) Parameter containing:
tensor([[-1.8485e-01, -1.1489e-01, -2.1878e-01, -1.3102e-01, -1.8931e-01,
          2.7378e-01, -1.9389e-01, -3.3245e-01, -2.0797e-01, -3.2712e-01,
         -1.7976e-01, -1.3682e-01,  4.2121e-02,  2.8227e-01, -2.5782e-02,
          3.4604e-01, -3.5088e-01,  1.4745e-01,  1.7322e-01,  2.7075e-01,
         -2.3573e-01,  1.1507e-01, -1.8458e-01,  1.4697e-01,  2.4829e-01,
          2.5140e-01, -3.3678e-01,  6.4661e-02, -1.4354e-02,  3.0885e-01,
         -5.8157e-02, -1.6139e-01],
        [-6.5146e-02, -2.1847e-01, -1.1328e-01, -2.3686e-01, -3.1119e-02,
          1.3503e-01, -3.2037e-01, -3.0969e-01, -9.3501e-02, -1.3067e-01,
         -1.3633e-01,  3.3529e-01,  2.8095e-01,  2.2632e-01,  7.8361e-02,
          2.3619e-01,  5.3799e-02, -3.7984e-02,  7.1996e-02,  3.5249e-01,
          1.6560e-01, -4.6318e-02,  2.7390e-01, -2.5174e-01,  2.5026e-01,
          1.4875e-01, -9.9013e-02,  3.0133e-01, -2.0392e-01, -3.4245e-01,
         -1.5026e-01, -1.9394e-01],
        [ 6.3528e-04,  2.9414e-01,  1.3021e-01, -2.5862e-01, -1.1394e-01,
         -1.6834e-01, -3.3869e-01, -3.5350e-01,  7.5450e-02, -1.5367e-01,
         -7.3217e-02, -2.3644e-01,  4.3089e-02, -1.1038e-01, -2.1055e-01,
         -3.3658e-01,  1.8795e-01,  3.1210e-01,  2.8153e-02, -3.0775e-01,
         -3.0654e-01, -2.3091e-01,  9.7058e-02, -3.1036e-01,  2.4245e-01,
          2.8001e-01,  8.6696e-05,  2.0604e-01, -1.4447e-01,  1.8248e-01,
         -2.9749e-01, -1.3872e-01],
        [ 2.6369e-01, -1.3927e-01, -2.5118e-01,  2.5134e-01, -1.8351e-01,
          1.4796e-01, -2.8681e-01,  1.9199e-01,  2.1052e-01,  1.5151e-01,
          2.0451e-01,  3.5289e-01,  2.0427e-01, -5.2420e-03, -2.6740e-02,
          1.3664e-01,  1.3122e-01, -1.5582e-01,  1.0056e-01,  3.4624e-01,
          3.2320e-01, -1.6391e-01,  3.1399e-01,  9.7661e-02, -9.9842e-02,
          2.8446e-01,  2.4416e-01,  2.9397e-01,  1.8749e-01,  1.7827e-01,
          1.7674e-02, -2.8192e-01],
        [-2.5249e-01, -1.7333e-01,  2.3459e-01,  1.3908e-01, -1.2200e-01,
         -1.2843e-01,  1.2114e-01,  2.3582e-01,  4.6236e-02, -2.8536e-01,
          2.6051e-01, -1.2891e-01, -4.3515e-02,  6.2177e-02, -2.1533e-01,
          2.4850e-01,  2.4280e-01, -2.5279e-01,  1.7761e-02, -8.0302e-02,
         -4.8966e-02, -1.3259e-01, -2.6776e-01,  5.2121e-02,  1.7692e-01,
          2.5974e-01,  1.7385e-01,  3.0818e-01, -2.3368e-01,  1.5101e-01,
         -3.4447e-01, -2.8226e-02],
        [-2.9034e-01, -7.1412e-02,  1.2730e-01,  1.7165e-01, -2.2468e-01,
          3.2655e-01,  3.0809e-01, -8.7772e-02, -2.1190e-01,  1.6563e-01,
         -1.5149e-02, -2.3167e-01,  2.8836e-01, -1.7862e-01,  2.8227e-01,
          5.5412e-02, -3.2829e-01, -3.0081e-01, -7.3364e-02,  3.3843e-01,
         -1.3146e-01,  2.3543e-01, -1.7632e-01,  6.3579e-02, -3.0364e-01,
          3.8337e-03,  2.4348e-01, -1.3293e-01,  3.1535e-02, -3.6956e-02,
         -3.5447e-02, -2.3651e-01],
        [ 1.0020e-01, -5.1718e-02, -3.4783e-01,  2.6218e-01,  3.3925e-02,
          4.6460e-02,  2.4083e-01,  1.9700e-01, -1.5082e-01,  2.0383e-01,
          1.6526e-01,  2.3307e-01, -1.5738e-01, -5.6037e-02,  2.2386e-01,
          2.7109e-01, -2.4766e-01, -5.3051e-03, -6.5559e-02,  2.7074e-01,
          2.1169e-01,  3.5245e-01, -2.2916e-01,  2.7552e-01,  2.2923e-01,
         -2.4314e-01,  2.7814e-01,  2.3339e-01,  1.9352e-01, -4.9997e-02,
          1.0573e-02,  1.1642e-02],
        [-2.5093e-01,  2.9009e-01,  2.2405e-01, -3.2424e-01,  2.8123e-02,
         -1.1027e-01,  5.3840e-02, -3.0163e-01, -2.6503e-01, -1.8220e-01,
         -3.6465e-02, -2.8531e-01,  1.9070e-01, -2.2831e-01, -3.6888e-02,
          7.0087e-02,  2.0511e-01,  2.8903e-01, -2.4323e-02, -1.3493e-01,
          1.4809e-01, -3.4893e-01, -1.9120e-01,  1.2281e-01, -2.4821e-01,
          3.5248e-01, -1.4979e-01,  3.3772e-01, -2.2698e-01,  1.1133e-01,
          4.6929e-02, -1.4806e-01],
        [ 3.2651e-01, -2.6805e-01, -1.2898e-01, -5.0790e-03, -2.8605e-01,
          1.6462e-01,  3.2375e-01, -1.4106e-02, -7.5468e-03, -2.4846e-01,
         -3.3398e-01, -2.0506e-01,  1.8064e-01, -1.0424e-01, -1.2183e-01,
         -2.9898e-01, -1.6405e-01, -2.3308e-01,  1.7226e-01, -1.6564e-01,
         -2.4525e-01, -2.0274e-01, -1.5735e-01,  2.5920e-01, -4.7970e-02,
          2.5120e-01, -5.7938e-02, -1.4128e-01, -1.5590e-01, -8.3982e-02,
         -2.3944e-01,  3.4119e-02],
        [-2.6530e-02, -2.2612e-01, -3.0463e-01,  3.0698e-01,  1.3980e-01,
         -1.9841e-01,  3.4905e-01,  1.8993e-01, -2.3547e-01,  1.5191e-02,
          3.1775e-02,  1.1824e-01, -9.1676e-02,  1.7147e-01,  3.1005e-01,
         -1.5874e-01,  2.5777e-02, -2.9038e-02, -5.6737e-02, -3.0945e-01,
          3.2270e-02,  2.7996e-01,  2.3155e-02, -2.1294e-01, -6.3012e-02,
         -2.4499e-01, -2.4015e-01,  1.9824e-01,  1.0763e-01, -2.8583e-01,
         -2.1152e-01, -5.2965e-02],
        [ 2.0151e-01, -8.0517e-02, -6.3371e-03,  2.0939e-01, -3.4566e-01,
          2.6916e-01,  2.2087e-01,  2.8127e-01,  3.5144e-01,  2.4323e-01,
          1.2511e-01,  2.7095e-01, -3.2172e-01,  9.1971e-02,  3.4482e-01,
         -2.5902e-01, -2.7533e-01, -2.9958e-01,  2.0563e-01,  5.4797e-02,
         -3.0412e-01,  2.5439e-01, -1.1755e-01,  7.0174e-02,  1.7394e-01,
          1.9477e-02, -2.6615e-02,  2.6787e-01, -1.8547e-01,  2.3566e-01,
         -7.5106e-02, -1.1240e-01],
        [-8.9359e-02,  1.8854e-01, -3.3419e-01, -3.3478e-02,  2.4404e-01,
         -1.3265e-01,  1.9152e-01, -2.0765e-01,  2.4961e-01,  6.9453e-03,
         -1.2719e-01,  2.9726e-01, -1.8079e-01, -1.1242e-01,  2.1874e-01,
          2.3904e-01, -1.3818e-01, -1.0493e-01,  8.8138e-02,  1.8328e-01,
         -1.7781e-01,  2.9178e-01, -2.7987e-01,  5.6194e-02, -4.7363e-03,
          7.4516e-02,  1.0538e-02, -2.8632e-01,  2.7613e-01,  3.0941e-01,
         -2.4401e-01,  2.6138e-01],
        [-2.3856e-01, -2.1773e-01, -1.7447e-01,  7.4491e-02,  2.1705e-01,
         -1.9012e-01,  3.0001e-01, -1.4377e-01,  1.2942e-01,  1.1436e-01,
         -3.3502e-01,  2.0245e-02,  2.1428e-01, -5.0778e-02, -2.0178e-01,
         -3.4696e-01,  5.5196e-02,  5.7292e-02,  3.3675e-01, -2.5322e-01,
         -1.8773e-01,  1.8308e-02,  6.7635e-02,  2.5198e-01,  1.5990e-01,
          2.5085e-01,  2.8888e-01,  1.1651e-01, -5.3521e-02, -9.7580e-02,
         -2.8644e-02,  8.6202e-02],
        [ 2.8262e-02,  3.3816e-01, -1.1566e-01,  1.3967e-01,  1.9851e-01,
         -2.4674e-01,  1.7776e-01, -2.0474e-01,  8.3060e-02, -1.1001e-01,
         -2.8385e-02,  2.7296e-01, -2.2991e-01,  1.6525e-02,  3.5312e-01,
         -1.0171e-02,  3.5136e-01, -2.0971e-01, -2.5932e-01, -9.7388e-02,
         -1.5658e-01,  2.0487e-01, -1.9237e-02, -6.1029e-02,  5.9416e-02,
          2.8571e-01, -1.7957e-01, -9.1238e-02,  4.1323e-02,  3.0108e-01,
         -1.8446e-01,  9.9333e-02],
        [-2.1377e-01, -2.0524e-01,  2.9482e-01, -1.4943e-01,  1.3398e-01,
          3.2869e-01,  2.5286e-01,  1.6669e-02,  3.1197e-01,  8.2556e-02,
         -5.9901e-02,  8.0276e-02, -2.5748e-01, -1.6481e-01, -1.2923e-01,
          1.2356e-01,  2.9785e-02,  9.3343e-02,  3.1934e-01,  6.8119e-03,
          2.6500e-01,  3.3801e-01,  9.7133e-02, -6.5781e-02, -2.1647e-01,
          2.9259e-01, -6.5076e-02, -1.9667e-01, -2.8367e-01,  1.5848e-01,
         -2.2623e-01,  2.7125e-01],
        [-1.9975e-01, -1.6775e-01,  3.3070e-01,  2.3086e-01,  3.2829e-01,
          4.6847e-02,  3.1474e-01, -5.6823e-02,  1.5456e-01,  7.8111e-02,
         -5.4831e-02,  1.1242e-01,  7.8074e-02, -1.4292e-01,  5.1181e-02,
          3.0938e-01,  1.8896e-01,  2.4033e-01,  4.3826e-02, -2.5298e-01,
         -4.1863e-02, -1.9449e-01,  1.1089e-01, -1.0665e-01, -7.8614e-02,
         -2.5355e-01,  6.8169e-02, -3.3891e-01,  2.5647e-02,  3.3823e-01,
          2.0803e-01, -2.0725e-01]], device='cuda:0', requires_grad=True)
outnn.net.2.resblock.2.bias torch.Size([16]) Parameter containing:
tensor([-0.0733, -0.1271, -0.1530,  0.1559, -0.1360, -0.1023, -0.0959,  0.1464,
        -0.0398, -0.1410, -0.0785,  0.0087, -0.1350, -0.1283,  0.0263,  0.0524],
       device='cuda:0', requires_grad=True)
outnn.net.2.resblock.3.alpha torch.Size([1, 16]) Parameter containing:
tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],
       device='cuda:0', requires_grad=True)
outnn.net.2.resblock.3.beta torch.Size([1, 16]) Parameter containing:
tensor([[0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312,
         0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312]],
       device='cuda:0', requires_grad=True)
outnn.net.2.resblock.4.weight torch.Size([16]) Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       device='cuda:0', requires_grad=True)
outnn.net.2.resblock.4.bias torch.Size([16]) Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
outnn.net.2.resblock.5.weight torch.Size([32, 16]) Parameter containing:
tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],
       device='cuda:0', requires_grad=True)
outnn.net.2.resblock.5.bias torch.Size([32]) Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
outnn.net.3.resblock.0.alpha torch.Size([1, 32]) Parameter containing:
tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],
       device='cuda:0', requires_grad=True)
outnn.net.3.resblock.0.beta torch.Size([1, 32]) Parameter containing:
tensor([[0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,
         0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,
         0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,
         0.0093, 0.0093, 0.0093, 0.0093, 0.0093]], device='cuda:0',
       requires_grad=True)
outnn.net.3.resblock.1.weight torch.Size([32]) Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       device='cuda:0', requires_grad=True)
outnn.net.3.resblock.1.bias torch.Size([32]) Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
outnn.net.3.resblock.2.weight torch.Size([16, 32]) Parameter containing:
tensor([[ 2.0956e-01, -2.6495e-01, -3.4788e-01,  1.2018e-01,  2.5784e-03,
          1.7366e-02, -5.2240e-02,  2.2994e-02,  2.6704e-01, -6.6114e-02,
         -2.1157e-02, -1.4024e-01,  1.4577e-01, -2.9210e-01,  3.1570e-01,
         -1.0504e-02, -2.5709e-01,  5.8714e-02,  8.0647e-02, -2.5288e-01,
         -1.0332e-01,  1.3005e-01,  3.1660e-01, -1.4922e-01, -7.4146e-02,
          3.1930e-01, -4.9464e-02, -1.4176e-01, -2.7314e-01, -3.0249e-01,
         -2.2637e-01,  1.6172e-01],
        [ 1.9137e-02, -2.7010e-01, -2.8192e-01,  1.7402e-01,  3.3581e-01,
         -2.6129e-01, -1.3929e-01, -5.9701e-02, -3.1809e-01,  3.2042e-01,
          2.8500e-01, -2.9466e-01, -2.8235e-01,  3.7257e-02, -2.7139e-01,
         -3.4532e-01, -2.0777e-01,  3.5065e-01, -2.9181e-01, -2.3969e-01,
          1.8675e-01,  3.3007e-01, -2.6468e-04,  1.7624e-01,  1.4514e-01,
         -3.0992e-01, -1.5572e-01, -2.9265e-01, -2.3990e-01,  1.8221e-01,
         -3.2488e-01, -1.6262e-01],
        [ 9.7191e-02,  2.2178e-01, -3.4271e-01,  2.3707e-01, -2.9189e-01,
         -1.7073e-01, -3.0456e-01,  1.1713e-01,  1.5527e-01,  2.8959e-01,
         -8.6124e-02, -2.2234e-02, -1.2404e-01, -1.8710e-01, -2.3723e-01,
          1.7642e-01,  3.0788e-01, -3.0867e-01, -3.1431e-01,  1.9575e-01,
          1.2173e-01, -2.3605e-02, -3.2356e-01,  2.9081e-01, -3.2544e-01,
          2.7653e-01,  1.9547e-01,  3.3249e-01, -2.1085e-01,  2.0632e-01,
          2.0034e-01,  2.3151e-01],
        [ 5.1469e-02, -2.0141e-01, -1.1556e-01,  6.5185e-03,  2.0984e-01,
         -7.1649e-02, -2.6061e-01,  4.5365e-02, -8.3918e-02,  3.3980e-01,
          2.1032e-01, -2.3380e-01, -2.9008e-01, -7.2049e-02,  2.4656e-01,
          1.2685e-01, -2.8818e-02,  3.2362e-01, -2.5985e-01, -2.1796e-01,
         -1.9953e-02,  1.2939e-01,  3.2875e-02, -5.1930e-02,  3.7359e-02,
         -1.4508e-01, -1.1785e-01, -7.9895e-02,  3.4614e-01,  1.0294e-01,
         -1.3449e-01, -1.6693e-01],
        [-2.9770e-01,  2.7992e-01, -2.5498e-01, -2.5112e-01,  1.3132e-01,
         -6.0946e-02, -3.4787e-01,  5.8339e-02, -7.9325e-03, -2.4715e-01,
          1.4829e-02,  9.4501e-02, -1.9791e-01, -3.3063e-01,  3.0364e-01,
         -2.8895e-01,  2.2429e-01,  2.7177e-01, -1.7701e-01, -1.6156e-01,
          3.0194e-01, -2.3556e-01,  1.2731e-02,  3.1618e-01,  2.8547e-01,
          2.8853e-01,  2.6933e-01,  1.4660e-01, -9.3379e-02, -2.1073e-03,
         -2.1424e-01, -6.8468e-03],
        [ 5.8398e-02, -2.1065e-01, -1.6947e-01,  2.5272e-02, -1.1425e-01,
          2.9660e-01, -1.2944e-01, -1.7545e-02,  4.3177e-02, -3.1148e-01,
          1.0284e-01, -8.2959e-03, -4.0642e-02,  2.8019e-01,  4.4960e-02,
         -3.0650e-01,  1.7110e-01,  2.7474e-01,  3.5128e-01,  1.0198e-01,
         -2.8492e-01,  1.9936e-02, -2.5173e-02,  1.2658e-01,  2.7445e-01,
         -1.4534e-01,  2.3837e-01,  1.8499e-01,  1.9756e-01, -1.3434e-01,
         -1.5759e-01,  2.2098e-01],
        [-3.1518e-01, -2.5480e-01,  2.6371e-01, -1.2312e-02,  1.2103e-01,
          3.3995e-01,  2.1626e-01, -1.6189e-01,  2.8011e-01, -2.1241e-01,
          1.0610e-03, -1.5811e-01, -6.7499e-02,  2.2845e-01,  1.0448e-01,
         -1.2617e-01,  3.5114e-02,  2.4846e-01,  2.2766e-01, -5.6359e-04,
          3.4869e-01,  2.0009e-01,  5.7275e-02,  1.0472e-01, -2.4857e-01,
         -2.1672e-01,  1.8211e-01, -2.9558e-01, -2.7086e-01,  8.1339e-03,
          2.5106e-01, -2.4775e-01],
        [ 1.0642e-01,  1.8716e-01, -2.5016e-02,  3.4503e-01, -2.3356e-01,
         -1.7599e-02,  1.0850e-02, -1.6477e-01,  5.8913e-03, -2.2529e-01,
          2.8344e-01, -2.4309e-01,  1.8465e-01,  3.1081e-01, -3.4448e-01,
          1.6475e-01, -1.1811e-01,  9.8184e-02, -1.3422e-01,  6.4700e-02,
          1.8956e-01,  1.4313e-02, -9.3324e-02,  1.5112e-01, -1.8709e-01,
          1.6019e-01, -5.6760e-02,  1.2887e-01, -3.4890e-01,  1.4349e-01,
         -5.8969e-02, -2.0258e-01],
        [ 1.1397e-01,  2.0846e-01,  2.0800e-01,  2.0004e-01,  1.8752e-01,
         -8.2471e-03,  1.6302e-01,  8.5632e-02,  5.7383e-02,  1.0521e-01,
          1.6407e-01, -1.0534e-01,  2.2248e-02,  1.9951e-01,  2.7453e-01,
         -3.5233e-01, -3.3268e-02, -2.1113e-01,  1.9235e-01,  2.2423e-01,
         -1.8468e-01, -3.1548e-01,  2.7743e-01,  1.2735e-01, -2.9507e-01,
         -1.5000e-01, -3.3417e-01, -1.8226e-01,  1.0797e-01, -2.4971e-01,
          1.1046e-01,  5.9080e-02],
        [-1.8710e-01,  2.3678e-01, -1.3828e-01,  1.1232e-01, -1.0164e-01,
          1.5054e-01, -1.4752e-01, -1.0913e-02,  3.2438e-01, -3.0454e-02,
         -1.6101e-01, -3.4424e-01, -8.6535e-02,  2.5478e-01, -1.6530e-01,
          1.2661e-01, -2.8703e-01, -1.8833e-01,  3.4732e-01,  5.7190e-02,
          1.8608e-01, -3.1265e-01, -3.1756e-01, -2.5662e-01,  3.1389e-01,
          1.6240e-01,  2.1934e-01,  2.9789e-01, -6.0739e-02,  1.5647e-01,
         -3.1594e-01,  1.7197e-01],
        [-1.9653e-01,  1.7344e-01,  5.9898e-02,  4.3116e-02,  5.2550e-03,
          2.6446e-01, -1.6681e-01,  1.2710e-01, -2.7956e-01,  3.1916e-01,
         -3.2982e-01, -6.0871e-02, -5.6423e-02, -8.7738e-02, -2.1189e-01,
         -1.4702e-01, -9.5113e-02,  2.4497e-01,  3.2088e-01, -8.9314e-02,
          2.8137e-01, -1.9730e-01,  8.9777e-02, -8.6216e-02, -1.7525e-02,
         -5.2705e-02, -2.0691e-01,  2.1563e-01,  2.2908e-01, -1.5726e-01,
         -1.0370e-01,  2.5555e-01],
        [-3.3917e-02,  2.0506e-01,  1.5557e-01, -2.9162e-01, -6.2150e-02,
         -2.3713e-01,  2.0070e-01, -1.1151e-02, -2.5470e-01,  6.7107e-02,
          3.3061e-01, -3.0965e-01,  1.9984e-01, -2.0294e-01,  2.9440e-01,
          6.3491e-02,  2.7057e-01, -1.2756e-01,  3.4308e-01, -1.3500e-01,
          2.8133e-01, -3.2109e-01,  8.0919e-02, -5.8017e-02,  1.0803e-01,
          6.6429e-02, -2.1656e-01, -3.3336e-01, -1.1457e-01, -3.0210e-01,
          3.1066e-02, -1.2933e-02],
        [ 2.6648e-01,  3.2349e-01, -2.3405e-01,  2.0835e-01,  2.4459e-01,
         -1.1998e-01, -1.9367e-01,  2.8872e-03,  6.0996e-02,  6.5236e-02,
         -1.8210e-02, -2.5628e-02, -2.2800e-01,  1.2150e-01, -2.0200e-01,
          1.1192e-01, -5.8005e-02, -1.0392e-02, -3.5632e-02, -2.4070e-01,
         -3.9672e-02, -1.6941e-01, -5.9450e-02,  2.7215e-01, -1.2997e-01,
         -1.8105e-01, -1.6205e-01, -3.2808e-01, -3.4755e-01,  3.2233e-01,
         -1.5154e-01,  3.6599e-02],
        [-2.6857e-01,  1.2038e-01,  5.4096e-02,  2.6624e-01,  5.9632e-02,
         -2.2532e-02, -5.4266e-02,  1.4680e-01,  6.5795e-02, -2.2238e-01,
          5.2398e-02,  3.0416e-01, -1.4821e-01, -2.0586e-01, -9.8427e-02,
          1.9849e-01,  1.6298e-01,  8.6697e-02, -3.0132e-02, -1.0170e-01,
          2.1108e-01, -5.1901e-02,  2.5288e-01, -2.1275e-01, -2.7880e-01,
          1.2106e-01, -3.1372e-01,  8.6870e-02,  7.7551e-02, -3.2482e-01,
          2.8084e-01,  2.2781e-01],
        [ 1.4246e-01,  2.6328e-01,  2.1093e-02,  8.5643e-02, -1.8416e-01,
         -1.1275e-01, -3.1713e-01, -5.0935e-02, -1.8824e-01,  2.2575e-01,
          2.7723e-01, -2.4886e-01, -3.1446e-01,  3.5237e-01, -2.6609e-01,
          2.6349e-01, -2.5602e-01, -3.3231e-01, -6.4545e-02,  2.9874e-01,
         -1.4589e-01, -2.7025e-01, -3.2338e-01,  7.9782e-02,  2.7262e-02,
         -9.0436e-02,  3.3779e-01,  1.3528e-01, -9.5775e-02,  3.0286e-01,
         -8.9070e-02, -8.5515e-02],
        [ 2.8394e-01,  1.0542e-01, -1.4890e-01,  2.2580e-01, -3.1834e-01,
          2.7476e-01, -2.5896e-01,  1.8473e-01,  8.6641e-02, -2.9474e-01,
         -1.9947e-02,  1.5847e-02,  2.9525e-01,  3.1574e-01,  1.1974e-01,
         -1.1178e-01,  3.8169e-02, -8.8374e-02,  1.4359e-01,  3.3109e-01,
          7.0911e-02,  3.2674e-01, -1.3435e-01, -1.8154e-01, -2.5001e-01,
         -2.7747e-01,  1.2764e-01, -2.6080e-01, -1.7847e-01, -3.3641e-01,
          1.6218e-01, -9.4483e-02]], device='cuda:0', requires_grad=True)
outnn.net.3.resblock.2.bias torch.Size([16]) Parameter containing:
tensor([ 0.0037,  0.0051,  0.1718,  0.0498,  0.1263, -0.1107, -0.0030, -0.1513,
         0.1070,  0.1187, -0.0488,  0.1388,  0.1377,  0.0545,  0.1268, -0.1464],
       device='cuda:0', requires_grad=True)
outnn.net.3.resblock.3.alpha torch.Size([1, 16]) Parameter containing:
tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],
       device='cuda:0', requires_grad=True)
outnn.net.3.resblock.3.beta torch.Size([1, 16]) Parameter containing:
tensor([[0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312,
         0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312]],
       device='cuda:0', requires_grad=True)
outnn.net.3.resblock.4.weight torch.Size([16]) Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       device='cuda:0', requires_grad=True)
outnn.net.3.resblock.4.bias torch.Size([16]) Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
outnn.net.3.resblock.5.weight torch.Size([32, 16]) Parameter containing:
tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],
       device='cuda:0', requires_grad=True)
outnn.net.3.resblock.5.bias torch.Size([32]) Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
outnn.net.4.alpha torch.Size([1, 32]) Parameter containing:
tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],
       device='cuda:0', requires_grad=True)
outnn.net.4.beta torch.Size([1, 32]) Parameter containing:
tensor([[0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,
         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,
         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,
         0.0625, 0.0625, 0.0625, 0.0625, 0.0625]], device='cuda:0',
       requires_grad=True)
outnn.net.5.weight torch.Size([1, 32]) Parameter containing:
tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0', requires_grad=True)
outnn.net.5.bias torch.Size([1]) Parameter containing:
tensor([1.], device='cuda:0', requires_grad=True)
